---
sidebar_position: 17
---

# Mixtral 8x7B Instruct v0.1

## 🚀 Model Overview

| Attribute           | Detail                             |
| :------------------ | :--------------------------------- |
| **Model Name**      | Mixtral 8x7B Instruct v0.1         |
| **Provider**        | Mistral AI                         |
| **Hosting**         | OTC                                |
| **Country**         | European Union 🇪🇺                 |
| **Parameter Count** | 12.9 billion active per token      |
| **Context Window**  | 32,768 tokens                      |

## ⚙️ Model Specifications

| Reasoning | Intelligence | Speed          | Input Formats         | Output Formats        | Price |
| :-------- | :----------- | :------------- | :-------------------- | :-------------------- | :---- |
| ❌ **No** | 🟡 **Medium**| ⚡⚡⚡ **Fast**  | ✅ Text               | ✅ Text               | €     |

## 📝 Description

Mixtral 8x7B Instruct v0.1 is a Sparse Mixture of Experts (SMoE) language model developed by Mistral AI. It consists of eight distinct expert groups, each with 7 billion parameters, totaling 46.7 billion parameters. However, during inference, only two experts are active per token, utilizing 12.9 billion parameters, which allows for efficient processing with the performance of a smaller model. The model supports a context window of 32,768 tokens and has been fine-tuned for instruction-following tasks, achieving a score of 8.3 on MT-Bench, comparable to GPT-3.5. It demonstrates strong performance in code generation and multilingual capabilities, handling languages such as English, French, Italian, German, and Spanish.

## ✅ Suitable Tasks

- Instruction Following
- Code Generation
- Multilingual Text Processing
- Creative Text Generation

## ✨ Feature Support

| Feature                | Availability     |
| :--------------------- | :--------------- |
| **Streaming**          | ✅ Supported     |
| **Function Calling**   | ✅ Supported     |
| **Structured Outputs** | ✅ Supported     |
| **Fine-tuning**        | ✅ Supported     |
| **Distillation**       | ❌ Not Supported |
| **Predicted Outputs**  | ✅ Supported     |
