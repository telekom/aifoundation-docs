---
sidebar_position: 1
---

# DeepSeek R1 Distill Llama 70B

## 🚀 Model Overview

| Attribute           | Detail                          |
| :------------------ | :------------------------------ |
| **Model Name**      | DeepSeek-R1-Distill-Llama-70B   |
| **Provider**        | DeepSeek                        |
| **Hosting**         | OTC                             |
| **Country**         | Germany 🇩🇪                     |
| **Parameter Count** | 70 billion                      |
| **Context Window**  | 128,000 tokens                  |

## ⚙️ Model Specifications

| Reasoning | Intelligence | Speed          | Input Formats | Output Formats | Price        |
| :-------- | :----------- | :------------- | :------------ | :------------- | :----------- |
| ✅ **Yes**| 🟢 **High**  | ⚡⚡ **Moderate**| ✅ Text       | ✅ Text        | €€    |

## 📝 Description

DeepSeek-R1-Distill-Llama-70B is a distilled version of the DeepSeek R1 model, built on top of the Llama 3.3 70B architecture. It retains strong reasoning and problem-solving capabilities while being more efficient for inference. With a large context window of 128,000 tokens, it is suitable for handling long-form documents, complex queries, and mathematical tasks. The model is hosted securely within T-Systems’ OpenTelekom Cloud (OTC), ensuring enterprise-grade availability and privacy.

## ✅ Suitable Tasks

- Mathematical & Logical Reasoning  
- Code Generation  
- Complex Instruction Following  
- Academic and Technical Use Cases

## ✨ Feature Support

| Feature                | Availability     |
| :--------------------- | :--------------- |
| **Streaming**          | ✅ Supported     |
| **Function Calling**   | ✅ Supported     |
| **Structured Outputs** | ✅ Supported     |
| **Fine-tuning**        | ✅ Supported     |
| **Distillation**       | ✅ Supported     |
| **Predicted Outputs**  | ✅ Supported     |
